{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f93e88-aabf-4dea-822c-1badf28bd583",
   "metadata": {},
   "source": [
    "# Load HR policy documents, split them, create embeddings and store them in a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0056e024-0c98-4037-8af3-485c2d12a1ed",
   "metadata": {},
   "source": [
    "## Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cee32e-8712-4f16-b499-00ef939ff0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2af86e-5a59-4c39-8e62-89173086b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain_community.document_loaders import (UnstructuredWordDocumentLoader, UnstructuredPDFLoader)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=400\n",
    ")\n",
    "\n",
    "folder_path = 'documents'\n",
    "all_files = os.listdir(folder_path)\n",
    "filtered_files = [os.path.join(folder_path, f) for f in all_files if re.search(\"(.pdf|.docx)$\", f, re.IGNORECASE)]\n",
    "\n",
    "def load_elements_from_file(file_path):\n",
    "    if file_path.lower().endswith('.pdf'):\n",
    "        loader = UnstructuredPDFLoader(file_path, strategy=\"hi_res\")\n",
    "    elif file_path.lower().endswith('.docx'):\n",
    "        loader = UnstructuredWordDocumentLoader(file_path, strategy=\"hi_res\")\n",
    "    else:\n",
    "        return None  # Ignore files that are not PDF or DOCX\n",
    "\n",
    "    data = loader.load_and_split(text_splitter=r_splitter)\n",
    "    # data = loader.load()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d50c8-1cc8-46be-8458-8cbaa28f46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for f in filtered_files:\n",
    "    elements = load_elements_from_file(f)\n",
    "    splits.extend(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625e688-ccc1-45ca-b8eb-e3e78a67c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047fc51e-eb69-4eb4-97d8-4cf4675191ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(splits[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618410c-3632-4450-9ac3-b349828eddb3",
   "metadata": {},
   "source": [
    "## Read OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9320a-77db-49d1-b4b3-0272483bb95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import langchain_openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca82cb-9833-4ee3-8448-a7a0a56fa051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600dafea-d781-44f1-b227-c20fb9f1eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637df1b5-ca64-40de-b96f-08bd7f52ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'chromadb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eabf91-1402-48be-9c2c-0d102b9e85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf persist_directory  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb904985-ed52-4100-aef2-dcca4b29d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e6595-266a-49f2-986d-ee28e7c19f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_chroma import Chroma\n",
    "# vectordb = Chroma(embedding_function=embedding, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649ed19-3d26-47f1-808e-b8d09b998586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73802a4-9a92-4c15-863e-6e62e50457ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Est-ce qu'il y a des heures pour utiliser la salle de fitness?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36f2a5-4f68-49cc-aa74-f74d14cbc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c2167-457d-42f6-b2fb-b698058fdec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = vectordb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a84374-70af-4913-8e09-50929c85f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029199ae-accd-42d6-be84-576b897efefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7578f9bc-ce53-4165-8fbe-7f383ff7914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c9faf-7259-4297-ba0a-c50fe2d5329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7a537-ee1b-41bb-9ec3-d674f00bf192",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc032875-c158-4a77-b071-bab82eecffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d096c8f-8ea2-4116-be9c-d1fd0372ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ed575-c920-4e94-90b6-1d7c542f5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {\n",
    "  \"prompts\": [\n",
    "    \"System: Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\nThe file mysealedsecret.[json|yaml] is a commitable file.\\n\\nIf you would rather not need access to the cluster to generate the sealed secret you can run:\\n\\n    kubeseal \\\\\\n\\n      --controller-name=sealed-secrets-controller \\\\\\n\\n      --controller-namespace=kube-system \\\\\\n\\n      --fetch-cert > mycert.pem\\n\\nto retrieve the public cert used for encryption and store it locally. You can then run 'kubeseal --cert mycert.pem' instead to use the local cert e.g.\\n\\n    kubectl create secret generic secret-name --dry-run=client --from-literal=foo=bar -o [json|yaml] | \\\\\\n\\n    kubeseal \\\\\\n\\n      --controller-name=sealed-secrets-controller \\\\\\n\\n      --controller-namespace=kube-system \\\\\\n\\n      --format [json|yaml] --cert mycert.pem > mysealedsecret.[json|yaml]\\n\\n3. Apply the sealed secret\\n\\n    kubectl create -f mysealedsecret.[json|yaml]\\n\\nRunning 'kubectl get secret secret-name -o [json|yaml]' will show the decrypted secret that was generated from the sealed secret.\\n\\nBoth the SealedSecret and generated Secret must have the same name and namespace.\\n\\nInstall client\\n\\n$ wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.24.4/kubeseal-0.24.4-linux-amd64.tar.gz\\n\\nUtilisation\\n\\n$ kubeseal -f postgres-pass-secret.yaml -w postgres-pass-secret-sealed.yaml\\n\\nMettre le secret dans .gitignore pour qu'il ne soit pas versionné. Le sealed secret par contre est encrypté et peut être versionné.\\n\\nUtilisation\\n\\n$ kubeseal -f postgres-pass-secret.yaml -w postgres-pass-secret-sealed.yaml\\n\\nMettre le secret dans .gitignore pour qu'il ne soit pas versionné. Le sealed secret par contre est encrypté et peut être versionné.\\n\\nDans le fichier kustomize.yaml mettre le sealed secret. A l'instanciation dans le cluster il sera transformé localement en secret utilisable dans les déploiements.\\n\\nAttention un secret n'est valable que pour un namespace.\\n\\nInstallation Nginx-Ingress (TLS)\\n\\n# Création du namespace\\n\\n$ k create ns nginx-ingress\\n\\n# Création du certificat TLS (en dry run pour garder le fichier)\\n\\n$ kubectl create secret tls star-marvinpac-com --key=star_marvinpac_com.key --cert=star_marvinpac_com.crt --dry-run=client -o yaml > mvp-tls-secret.yaml\\n\\n# Importation du certificat\\n\\n$ k apply -n nginx-ingress -f mvp-tls-secret.yaml\\n\\n# Supprimer le helm chart s'il existe déjà\\n\\n$ helm uninstall ingress-nginx ingress-nginx/ingress-nginx --namespace ingress-nginx\\n\\n# Installer le helm chart\\n\\n$ helm install ingress-nginx ingress-nginx/ingress-nginx --namespace ingress-nginx  --set controller.wildcardTLS.cert=ingress-nginx/star-marvinpac-com --set controller.service.loadBalancerIP=192.168.77.149 --set controller.config.force-ssl-redirect=\\\"true\\\"\\n\\n# Vérifier que la config force-ssl-redirect\\n\\n$ k get cm -n nginx-ingress ingress-nginx-controller -o yaml\\n\\nAn example Ingress that makes use of the controller:\\n\\n  apiVersion: networking.k8s.io/v1\\n\\n  kind: Ingress\\n\\n  metadata:\\n\\n    name: example\\n\\nTo get the password for \\\"repmgr\\\" run:\\n\\n    export REPMGR_PASSWORD=$(kubectl get secret --namespace analytics postgres-ha-postgresql-ha-postgresql -o jsonpath=\\\"{.data.repmgr-password}\\\" | base64 -d)\\n\\nTo connect to your database run the following command:\\n\\n    kubectl run postgres-ha-postgresql-ha-client --rm --tty -i --restart='Never' --namespace analytics --image docker.io/bitnami/postgresql-repmgr:16.3.0-debian-12-r11 --env=\\\"PGPASSWORD=$POSTGRES_PASSWORD\\\"  \\\\\\n\\n        --command -- psql -h postgres-ha-postgresql-ha-pgpool -p 5432 -U postgres -d postgres\\n\\nTo connect to your database from outside the cluster execute the following commands:\\n\\n  NOTE: It may take a few minutes for the LoadBalancer IP to be available.\\n\\n        Watch the status with: 'kubectl get svc --namespace analytics -w postgres-ha-postgresql-ha-pgpool\\n\\n    export SERVICE_IP=$(kubectl get svc --namespace analytics postgres-ha-postgresql-ha-pgpool --template \\\"{{ range (index .status.loadBalancer.ingress 0) }}{{ . }}{{ end }}\\\")\\n\\n    PGPASSWORD=\\\"$POSTGRES_PASSWORD\\\" psql -h $SERVICE_IP -p 5432  -U postgres -d postgres\\n\\nWARNING: There are \\\"resources\\\" sections in the chart not set. Using \\\"resourcesPreset\\\" is not recommended for production. For production installations, please set the following values according to your workload needs:\\n\\n- pgpool.resources\\n\\n- postgresql.resources\\n\\n- witness.resources\\n\\n+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\\n\\nK8S Find unmounted PVCs\\n\\ncsi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph\\n\\n  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node\\n\\n  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph\\n\\nreclaimPolicy: Delete\\n\\nInstall sealed-secrets\\n\\nInstall server\\n\\n$ helm repo add sealed-secrets https://bitnami-labs.github.io/sealed-secrets\\n\\n$ help repo update\\n\\n$ helm install sealed-secrets -n kube-system --set-string fullnameOverride=sealed-secrets-controller sealed-secrets/sealed-secrets\\n\\nNAME: sealed-secrets\\n\\nLAST DEPLOYED: Thu Nov 16 12:49:03 2023\\n\\nNAMESPACE: kube-system\\n\\nSTATUS: deployed\\n\\nREVISION: 1\\n\\nTEST SUITE: None\\n\\nNOTES:\\n\\n** Please be patient while the chart is being deployed **\\n\\nYou should now be able to create sealed secrets.\\n\\n1. Install the client-side tool (kubeseal) as explained in the docs below:\\n\\n    https://github.com/bitnami-labs/sealed-secrets#installation-from-source\\n\\n2. Create a sealed secret file running the command below:\\n\\n    kubectl create secret generic secret-name --dry-run=client --from-literal=foo=bar -o [json|yaml] | \\\\\\n\\n    kubeseal \\\\\\n\\n      --controller-name=sealed-secrets-controller \\\\\\n\\n      --controller-namespace=kube-system \\\\\\n\\n      --format yaml > mysealedsecret.[json|yaml]\\n\\nThe file mysealedsecret.[json|yaml] is a commitable file.\\n\\nIf you would rather not need access to the cluster to generate the sealed secret you can run:\\n\\n    kubeseal \\\\\\n\\n      --controller-name=sealed-secrets-controller \\\\\\n\\n      --controller-namespace=kube-system \\\\\\nHuman: How do I seal a password using kubeseal?\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970bba3a-a134-4108-bddb-fb762bdabc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mydict[\"prompts\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa4c5e-4053-4314-b952-f676724626f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "el = load_elements_from_file(\"C:/Users/olivier.boudry/Downloads/KB-214.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97814fa7-de90-4969-b176-19c29abdc027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
